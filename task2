import numpy as np
import matplotlib.pyplot
import time



def convert(imgs, labels, outfile, n):
    imgf = open(imgs, "rb")
    labelf = open(labels,"rb")
    csvf = open(outfile, "w")
    
    imgf.read(16)
    labelf.read(8)
    images = []
    
    for i in range(n):
        image = [ord(labelf.read(1))]
        for j in range(28*28):
            image.append(ord(imgf.read(1)))
        images.append(image)
        
    for image in images:
        csvf.write(",".join(str(pix) for pix in image) + "\n")
    imgf.close()
    labelf.close()
    csvf.close()

mnist_train_x = "C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\train-images.idx3-ubyte"
mnist_train_y = "C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\train-labels.idx1-ubyte"
mnist_test_x = "C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\t10k-images.idx3-ubyte"
mnist_test_y = "C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\t10k-labels.idx1-ubyte"


convert(mnist_train_x, mnist_train_y, "C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\train.csv", 60000)
convert(mnist_test_x, mnist_test_y,"C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\test.csv", 10000)

train_file = open("C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\train.csv", "r")
train_list = train_file.readlines()
train_file.close()
test_file = open("C:\\Users\\alejo\\OneDrive\\Desktop\\AI\\Task2\\test.csv", "r")
test_list = test_file.readlines()
test_file.close()
print(len(test_list))

#train_list[100]

values = test_list[1000].split(",")
image_array = np.asfarray(values[1:]).reshape((28,28))
matplotlib.pyplot.imshow(image_array, cmap="Greys", interpolation="None")


#Network

class DNN:
    def __init__ (self, sizes=[784,128,64,10], epochs=10, lr=0.001):
        self.sizes = sizes
        self.epochs = epochs
        self.lr = lr
        
        input_layer = sizes[0]
        hidden_1 = sizes[1]
        hidden_2 = sizes[2]
        output_layer = sizes[3]
        
        self.params = {
            'W1' : np.random.randn(hidden_1, input_layer)*np.sqrt(1./hidden_1),
            "W2" : np.random.randn(hidden_2, hidden_1)*np.sqrt(1./hidden_2),
            'W3' : np.random.randn(output_layer, hidden_2)*np.sqrt(1./output_layer)
            }
        
        
        
        
    def sigmoid(self, x, derivative=False):
        if derivative:
            return (np.exp(-x))/((np.exp(-x)+1)**2)
        return 1/(1+np.exp(-x))
    
    def ReLU(Z):
        return np.maximum(0,Z)
    
    def der_ReLU(Z):
        return Z>0
    
    def softmax(self, x, derivative=False):
        exps = np.exp(x-x.max())
        if derivative:
            return exps/np.sum(exps,axis=0)*(1-exps/np.sum(exps,axis=0))
        return exps/np.sum(exps,axis=0)
    
    def forward_pass(self, x_train):
        params = self.params
        
        params['A0'] = x_train
        
        
        #input layer to first hidden layer
        
        params['Z1'] = np.dot(params['W1'], params['A0'])
        params['A1'] = self.sigmoid(params['Z1'])
        
        
        #first hidden layer to second hidden layer
        params['Z2'] = np.dot(params['W2'], params['A1']) 
        params['A2'] = self.sigmoid(params['Z2'])
        
        #second hidden layer to output layer
        params['Z3'] = np.dot(params['W3'], params['A2'])
        params['A3'] = self.softmax(params['Z3'])
        
        return params['A3']
    
    def backward_pass(self, y_train, output):
        params = self.params
        
        change_w = {}
        #calculate w3 update
        
        error = 2*(output-y_train)/output.shape[0]*self.softmax(params['Z3'], derivative = True)
        change_w['W3'] = np.outer(error, params['A2'])
        
        #calculate w2
        error=np.dot(params['W3'].T, error)*self.sigmoid(params['Z2'], derivative=True)
        change_w['W2'] = np.outer(error,params['A1'])
        
        #calculate w1
        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)
        change_w['W1'] = np.outer(error,params['A0'])
        
        return change_w
    
    
    def update_w(self, change_w):
        for key,val in change_w.items():
            self.params[key] -= self.lr*val
    
    def compute_accuracy(self, test):
        for x in test:
            predictionList = []
            values = x.split(",")
            #Normalizing values in the array
            inputs = (np.asfarray(values[1:])/(255.0*0.99) + 1.0)
            #calculating error during backward pass
            targets = np.zeros(10) + 0.01
            targets[int (values[0])] = 0.99
            output = self.forward_pass(inputs)
            prediction = np.argmax(output)
            predictionList.append(prediction==np.argmax(targets))
        return np.mean(predictionList)
    
    def train(self, train_list, test_list):
        startT = time.time()
        for i in range (self.epochs):
            #parses all the training images to the network, also updating the params
            for x in train_list:
                values = x.split(",")
                #Normalizing values in the array
                inputs = (np.asfarray(values[1:])/(255.0*0.99) + 1.0)
                #calculating error during backward pass
                targets = np.zeros(10) + 0.01
                targets[int (values[0])] = 0.99
                output = self.forward_pass(inputs)
                change_w = self.backward_pass(targets, output)
                self.update_w(change_w)
            accuracy = self.computeAccuracy(test_list)
            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(
              i+1, time.time() - startT, accuracy * 100))
                
    
dnn = DNN ([784,128,64,10], epochs=10, lr=0.001)
dnn.train(train_list, test_list)

